/**
 * æ—¥å¿—åˆ†æå¹³å°
 * 
 * æä¾›æ—¥å¿—èšåˆã€åˆ†æã€å¯è§†åŒ–å’Œæ™ºèƒ½å‘Šè­¦åŠŸèƒ½
 */

import { LogEntry, LogLevel, LogType } from './structuredLogger'

/**
 * æ—¥å¿—åˆ†æé…ç½®
 */
export interface LogAnalysisConfig {
  aggregationInterval: number // èšåˆé—´éš”ï¼ˆæ¯«ç§’ï¼‰
  retentionPeriod: number     // æ•°æ®ä¿ç•™æœŸï¼ˆæ¯«ç§’ï¼‰
  alertThresholds: {
    errorRate: number         // é”™è¯¯ç‡é˜ˆå€¼
    warningRate: number       // è­¦å‘Šç‡é˜ˆå€¼
    responseTime: number      // å“åº”æ—¶é—´é˜ˆå€¼
  }
  enableRealTimeAnalysis: boolean
  enablePatternDetection: boolean
  enableAnomalyDetection: boolean
}

/**
 * æ—¥å¿—èšåˆæ•°æ®
 */
export interface LogAggregation {
  timestamp: number
  interval: number
  counts: {
    total: number
    byLevel: Record<LogLevel, number>
    byType: Record<LogType, number>
  }
  metrics: {
    errorRate: number
    warningRate: number
    averageResponseTime: number
    uniqueUsers: number
    uniqueSessions: number
  }
  topErrors: Array<{
    message: string
    count: number
    lastSeen: number
  }>
  patterns: Array<{
    pattern: string
    count: number
    confidence: number
  }>
}

/**
 * æ—¥å¿—æ¨¡å¼
 */
export interface LogPattern {
  id: string
  pattern: RegExp
  name: string
  description: string
  severity: LogLevel
  count: number
  lastMatch: number
  examples: LogEntry[]
}

/**
 * å¼‚å¸¸æ£€æµ‹ç»“æœ
 */
export interface AnomalyDetection {
  timestamp: number
  type: 'spike' | 'drop' | 'pattern' | 'threshold'
  metric: string
  value: number
  expected: number
  deviation: number
  confidence: number
  description: string
}

/**
 * æ—¥å¿—åˆ†æå™¨
 */
export class LogAnalyzer {
  private static instance: LogAnalyzer
  private config: LogAnalysisConfig
  private logBuffer: LogEntry[] = []
  private aggregations: LogAggregation[] = []
  private patterns: Map<string, LogPattern> = new Map()
  private anomalies: AnomalyDetection[] = []
  private analysisTimer?: number
  private isAnalyzing = false
  
  private constructor() {
    this.config = this.getDefaultConfig()
    this.initializePatterns()
    this.startAnalysis()
  }
  
  static getInstance(): LogAnalyzer {
    if (!LogAnalyzer.instance) {
      LogAnalyzer.instance = new LogAnalyzer()
    }
    return LogAnalyzer.instance
  }
  
  /**
   * é…ç½®åˆ†æå™¨
   */
  configure(config: Partial<LogAnalysisConfig>): void {
    this.config = { ...this.config, ...config }
    this.restartAnalysis()
  }
  
  /**
   * æ·»åŠ æ—¥å¿—æ¡ç›®è¿›è¡Œåˆ†æ
   */
  addLogEntry(entry: LogEntry): void {
    this.logBuffer.push(entry)

    // å®æ—¶åˆ†æ
    if (this.config.enableRealTimeAnalysis) {
      this.performRealTimeAnalysis(entry)
    }

    // é™åˆ¶ç¼“å†²åŒºå¤§å°
    if (this.logBuffer.length > 10000) {
      this.logBuffer.shift()
    }
  }

  /**
   * æ¸…ç†æ‰€æœ‰æ•°æ®ï¼ˆç”¨äºæµ‹è¯•ï¼‰
   */
  clearAllData(): void {
    this.logBuffer = []
    this.aggregations = []
    this.patterns.clear()
    this.anomalies = []
    this.initializePatterns()
  }
  
  /**
   * æ‰¹é‡æ·»åŠ æ—¥å¿—æ¡ç›®
   */
  addLogEntries(entries: LogEntry[]): void {
    entries.forEach(entry => this.addLogEntry(entry))
  }
  
  /**
   * è·å–æ—¥å¿—èšåˆæ•°æ®
   */
  getAggregations(startTime?: number, endTime?: number): LogAggregation[] {
    let filtered = this.aggregations
    
    if (startTime) {
      filtered = filtered.filter(agg => agg.timestamp >= startTime)
    }
    
    if (endTime) {
      filtered = filtered.filter(agg => agg.timestamp <= endTime)
    }
    
    return filtered.sort((a, b) => b.timestamp - a.timestamp)
  }
  
  /**
   * è·å–æœ€æ–°èšåˆæ•°æ®
   */
  getLatestAggregation(): LogAggregation | null {
    return this.aggregations.length > 0 ? this.aggregations[this.aggregations.length - 1] : null
  }
  
  /**
   * æœç´¢æ—¥å¿—
   */
  searchLogs(query: {
    level?: LogLevel
    type?: LogType
    message?: string
    userId?: string
    sessionId?: string
    tags?: string[]
    startTime?: number
    endTime?: number
    limit?: number
  }): LogEntry[] {
    let results = this.logBuffer.filter(entry => {
      if (query.level !== undefined && entry.level !== query.level) return false
      if (query.type && entry.type !== query.type) return false
      if (query.message && !entry.message.toLowerCase().includes(query.message.toLowerCase())) return false
      if (query.userId && entry.metadata.userId !== query.userId) return false
      if (query.sessionId && entry.metadata.sessionId !== query.sessionId) return false
      if (query.tags && !query.tags.every(tag => entry.tags.includes(tag))) return false
      if (query.startTime && entry.timestamp < query.startTime) return false
      if (query.endTime && entry.timestamp > query.endTime) return false
      return true
    })
    
    // æŒ‰æ—¶é—´å€’åºæ’åˆ—
    results.sort((a, b) => b.timestamp - a.timestamp)
    
    // é™åˆ¶ç»“æœæ•°é‡
    if (query.limit) {
      results = results.slice(0, query.limit)
    }
    
    return results
  }
  
  /**
   * è·å–é”™è¯¯è¶‹åŠ¿
   */
  getErrorTrend(timeWindow = 3600000): Array<{ timestamp: number; count: number }> {
    const now = Date.now()
    const startTime = now - timeWindow
    
    const errorLogs = this.logBuffer.filter(entry => 
      entry.level >= LogLevel.ERROR && entry.timestamp >= startTime
    )
    
    // æŒ‰å°æ—¶åˆ†ç»„
    const hourlyGroups = new Map<number, number>()
    
    errorLogs.forEach(entry => {
      const hour = Math.floor(entry.timestamp / 3600000) * 3600000
      hourlyGroups.set(hour, (hourlyGroups.get(hour) || 0) + 1)
    })
    
    return Array.from(hourlyGroups.entries())
      .map(([timestamp, count]) => ({ timestamp, count }))
      .sort((a, b) => a.timestamp - b.timestamp)
  }
  
  /**
   * è·å–ç”¨æˆ·æ´»åŠ¨åˆ†æ
   */
  getUserActivityAnalysis(): {
    activeUsers: number
    activeSessions: number
    topUsers: Array<{ userId: string; logCount: number }>
    userDistribution: Record<string, number>
  } {
    const userLogs = new Map<string, number>()
    const sessions = new Set<string>()

    this.logBuffer.forEach(entry => {
      // æ£€æŸ¥å¤šä¸ªå¯èƒ½çš„ç”¨æˆ·IDæ¥æº
      let userId = entry.metadata.userId
      if (!userId && entry.context && entry.context.userId) {
        userId = entry.context.userId as string
      }

      if (userId) {
        userLogs.set(userId, (userLogs.get(userId) || 0) + 1)
      }

      if (entry.metadata.sessionId) {
        sessions.add(entry.metadata.sessionId)
      }
    })

    const topUsers = Array.from(userLogs.entries())
      .map(([userId, logCount]) => ({ userId, logCount }))
      .sort((a, b) => b.logCount - a.logCount)
      .slice(0, 10)

    const userDistribution: Record<string, number> = {}
    userLogs.forEach((count, userId) => {
      const range = count < 10 ? '1-10' : count < 50 ? '11-50' : count < 100 ? '51-100' : '100+'
      userDistribution[range] = (userDistribution[range] || 0) + 1
    })

    return {
      activeUsers: userLogs.size,
      activeSessions: sessions.size,
      topUsers,
      userDistribution
    }
  }
  
  /**
   * è·å–æ€§èƒ½åˆ†æ
   */
  getPerformanceAnalysis(): {
    averageResponseTime: number
    slowestOperations: Array<{ operation: string; duration: number; timestamp: number }>
    performanceTrend: Array<{ timestamp: number; averageTime: number }>
  } {
    const performanceLogs = this.logBuffer.filter(entry => 
      entry.type === LogType.PERFORMANCE && entry.duration !== undefined
    )
    
    const totalDuration = performanceLogs.reduce((sum, entry) => sum + (entry.duration || 0), 0)
    const averageResponseTime = performanceLogs.length > 0 ? totalDuration / performanceLogs.length : 0
    
    const slowestOperations = performanceLogs
      .sort((a, b) => (b.duration || 0) - (a.duration || 0))
      .slice(0, 10)
      .map(entry => ({
        operation: entry.message,
        duration: entry.duration || 0,
        timestamp: entry.timestamp
      }))
    
    // æŒ‰å°æ—¶è®¡ç®—æ€§èƒ½è¶‹åŠ¿
    const hourlyPerformance = new Map<number, { total: number; count: number }>()
    
    performanceLogs.forEach(entry => {
      const hour = Math.floor(entry.timestamp / 3600000) * 3600000
      const current = hourlyPerformance.get(hour) || { total: 0, count: 0 }
      current.total += entry.duration || 0
      current.count += 1
      hourlyPerformance.set(hour, current)
    })
    
    const performanceTrend = Array.from(hourlyPerformance.entries())
      .map(([timestamp, data]) => ({
        timestamp,
        averageTime: data.count > 0 ? data.total / data.count : 0
      }))
      .sort((a, b) => a.timestamp - b.timestamp)
    
    return {
      averageResponseTime,
      slowestOperations,
      performanceTrend
    }
  }
  
  /**
   * è·å–æ£€æµ‹åˆ°çš„æ¨¡å¼
   */
  getDetectedPatterns(): LogPattern[] {
    return Array.from(this.patterns.values())
      .sort((a, b) => b.count - a.count)
  }
  
  /**
   * è·å–å¼‚å¸¸æ£€æµ‹ç»“æœ
   */
  getAnomalies(limit = 50): AnomalyDetection[] {
    return this.anomalies
      .sort((a, b) => b.timestamp - a.timestamp)
      .slice(0, limit)
  }
  
  /**
   * ç”Ÿæˆåˆ†ææŠ¥å‘Š
   */
  generateAnalysisReport(): string {
    const latest = this.getLatestAggregation()
    const userActivity = this.getUserActivityAnalysis()
    const performance = this.getPerformanceAnalysis()
    const patterns = this.getDetectedPatterns()
    const anomalies = this.getAnomalies(5)
    
    const report = [
      '# æ—¥å¿—åˆ†ææŠ¥å‘Š',
      '',
      `**ç”Ÿæˆæ—¶é—´**: ${new Date().toLocaleString()}`,
      `**åˆ†ææ—¶é—´çª—å£**: ${this.config.aggregationInterval / 1000}ç§’`,
      '',
      '## æ€»ä½“ç»Ÿè®¡',
      '',
      `- æ€»æ—¥å¿—æ•°: ${latest?.counts.total || 0}`,
      `- é”™è¯¯ç‡: ${((latest?.metrics.errorRate || 0) * 100).toFixed(2)}%`,
      `- è­¦å‘Šç‡: ${((latest?.metrics.warningRate || 0) * 100).toFixed(2)}%`,
      `- å¹³å‡å“åº”æ—¶é—´: ${performance.averageResponseTime.toFixed(2)}ms`,
      '',
      '## ç”¨æˆ·æ´»åŠ¨',
      '',
      `- æ´»è·ƒç”¨æˆ·: ${userActivity.activeUsers}`,
      `- æ´»è·ƒä¼šè¯: ${userActivity.activeSessions}`,
      `- æœ€æ´»è·ƒç”¨æˆ·: ${userActivity.topUsers.slice(0, 3).map(u => `${u.userId}(${u.logCount})`).join(', ')}`,
      '',
      '## æ£€æµ‹åˆ°çš„æ¨¡å¼',
      '',
      ...patterns.slice(0, 5).map((pattern, index) => 
        `${index + 1}. ${pattern.name}: ${pattern.count}æ¬¡ (${pattern.description})`
      ),
      '',
      '## æœ€è¿‘å¼‚å¸¸',
      '',
      ...anomalies.map((anomaly, index) => 
        `${index + 1}. ${anomaly.type}: ${anomaly.description} (ç½®ä¿¡åº¦: ${(anomaly.confidence * 100).toFixed(1)}%)`
      ),
      '',
      '## æ€§èƒ½åˆ†æ',
      '',
      `- å¹³å‡å“åº”æ—¶é—´: ${performance.averageResponseTime.toFixed(2)}ms`,
      `- æœ€æ…¢æ“ä½œ: ${performance.slowestOperations.slice(0, 3).map(op => `${op.operation}(${op.duration}ms)`).join(', ')}`,
      ''
    ]
    
    return report.join('\n')
  }
  
  // ç§æœ‰æ–¹æ³•
  private startAnalysis(): void {
    this.isAnalyzing = true
    this.analysisTimer = window.setInterval(() => {
      this.performPeriodicAnalysis()
    }, this.config.aggregationInterval)
  }
  
  private restartAnalysis(): void {
    this.stopAnalysis()
    this.startAnalysis()
  }
  
  private stopAnalysis(): void {
    this.isAnalyzing = false
    if (this.analysisTimer) {
      clearInterval(this.analysisTimer)
    }
  }
  
  private performPeriodicAnalysis(): void {
    const now = Date.now()
    const windowStart = now - this.config.aggregationInterval
    
    // è·å–æ—¶é—´çª—å£å†…çš„æ—¥å¿—
    const windowLogs = this.logBuffer.filter(entry => 
      entry.timestamp >= windowStart && entry.timestamp <= now
    )
    
    if (windowLogs.length === 0) return
    
    // åˆ›å»ºèšåˆæ•°æ®
    const aggregation = this.createAggregation(windowLogs, windowStart, this.config.aggregationInterval)
    this.aggregations.push(aggregation)
    
    // é™åˆ¶èšåˆæ•°æ®æ•°é‡
    if (this.aggregations.length > 1000) {
      this.aggregations.shift()
    }
    
    // æ¨¡å¼æ£€æµ‹
    if (this.config.enablePatternDetection) {
      this.detectPatterns(windowLogs)
    }
    
    // å¼‚å¸¸æ£€æµ‹
    if (this.config.enableAnomalyDetection) {
      this.detectAnomalies(aggregation)
    }
    
    // æ¸…ç†è¿‡æœŸæ•°æ®
    this.cleanupExpiredData()
  }
  
  private performRealTimeAnalysis(entry: LogEntry): void {
    // å®æ—¶æ¨¡å¼åŒ¹é…
    this.matchPatterns(entry)
    
    // å®æ—¶å¼‚å¸¸æ£€æµ‹
    if (entry.level >= LogLevel.ERROR) {
      this.checkErrorSpike()
    }
  }
  
  private createAggregation(logs: LogEntry[], timestamp: number, interval: number): LogAggregation {
    const counts = {
      total: logs.length,
      byLevel: {} as Record<LogLevel, number>,
      byType: {} as Record<LogType, number>
    }
    
    const users = new Set<string>()
    const sessions = new Set<string>()
    const errors = new Map<string, number>()
    let totalResponseTime = 0
    let responseTimeCount = 0
    
    logs.forEach(entry => {
      // æŒ‰çº§åˆ«ç»Ÿè®¡
      counts.byLevel[entry.level] = (counts.byLevel[entry.level] || 0) + 1
      
      // æŒ‰ç±»å‹ç»Ÿè®¡
      counts.byType[entry.type] = (counts.byType[entry.type] || 0) + 1
      
      // ç”¨æˆ·å’Œä¼šè¯ç»Ÿè®¡
      if (entry.metadata.userId) users.add(entry.metadata.userId)
      if (entry.metadata.sessionId) sessions.add(entry.metadata.sessionId)
      
      // é”™è¯¯ç»Ÿè®¡
      if (entry.level >= LogLevel.ERROR) {
        errors.set(entry.message, (errors.get(entry.message) || 0) + 1)
      }
      
      // å“åº”æ—¶é—´ç»Ÿè®¡
      if (entry.duration) {
        totalResponseTime += entry.duration
        responseTimeCount++
      }
    })
    
    const errorCount = (counts.byLevel[LogLevel.ERROR] || 0) + (counts.byLevel[LogLevel.FATAL] || 0)
    const warningCount = counts.byLevel[LogLevel.WARN] || 0
    
    return {
      timestamp,
      interval,
      counts,
      metrics: {
        errorRate: logs.length > 0 ? errorCount / logs.length : 0,
        warningRate: logs.length > 0 ? warningCount / logs.length : 0,
        averageResponseTime: responseTimeCount > 0 ? totalResponseTime / responseTimeCount : 0,
        uniqueUsers: users.size,
        uniqueSessions: sessions.size
      },
      topErrors: Array.from(errors.entries())
        .sort((a, b) => b[1] - a[1])
        .slice(0, 10)
        .map(([message, count]) => ({
          message,
          count,
          lastSeen: Math.max(...logs.filter(l => l.message === message).map(l => l.timestamp))
        })),
      patterns: []
    }
  }
  
  private initializePatterns(): void {
    const defaultPatterns = [
      {
        id: 'sql_error',
        pattern: /SQL.*error|database.*error|connection.*failed/i,
        name: 'SQLé”™è¯¯',
        description: 'æ•°æ®åº“ç›¸å…³é”™è¯¯',
        severity: LogLevel.ERROR
      },
      {
        id: 'auth_failure',
        pattern: /authentication.*failed|unauthorized|access.*denied/i,
        name: 'è®¤è¯å¤±è´¥',
        description: 'ç”¨æˆ·è®¤è¯æˆ–æˆæƒå¤±è´¥',
        severity: LogLevel.WARN
      },
      {
        id: 'timeout',
        pattern: /timeout|timed.*out|request.*timeout/i,
        name: 'è¶…æ—¶é”™è¯¯',
        description: 'è¯·æ±‚æˆ–æ“ä½œè¶…æ—¶',
        severity: LogLevel.ERROR
      },
      {
        id: 'memory_leak',
        pattern: /out.*of.*memory|memory.*leak|heap.*overflow/i,
        name: 'å†…å­˜é—®é¢˜',
        description: 'å†…å­˜ä¸è¶³æˆ–æ³„æ¼',
        severity: LogLevel.FATAL
      }
    ]
    
    defaultPatterns.forEach(pattern => {
      this.patterns.set(pattern.id, {
        ...pattern,
        count: 0,
        lastMatch: 0,
        examples: []
      })
    })
  }
  
  private detectPatterns(logs: LogEntry[]): void {
    logs.forEach(entry => this.matchPatterns(entry))
  }
  
  private matchPatterns(entry: LogEntry): void {
    this.patterns.forEach(pattern => {
      if (pattern.pattern.test(entry.message)) {
        pattern.count++
        pattern.lastMatch = entry.timestamp
        
        // ä¿ç•™æœ€è¿‘çš„ç¤ºä¾‹
        pattern.examples.push(entry)
        if (pattern.examples.length > 5) {
          pattern.examples.shift()
        }
      }
    })
  }
  
  private detectAnomalies(aggregation: LogAggregation): void {
    // æ£€æŸ¥é”™è¯¯ç‡å¼‚å¸¸
    if (aggregation.metrics.errorRate > this.config.alertThresholds.errorRate) {
      this.anomalies.push({
        timestamp: aggregation.timestamp,
        type: 'threshold',
        metric: 'error_rate',
        value: aggregation.metrics.errorRate,
        expected: this.config.alertThresholds.errorRate,
        deviation: aggregation.metrics.errorRate - this.config.alertThresholds.errorRate,
        confidence: 0.9,
        description: `é”™è¯¯ç‡ ${(aggregation.metrics.errorRate * 100).toFixed(2)}% è¶…è¿‡é˜ˆå€¼ ${(this.config.alertThresholds.errorRate * 100).toFixed(2)}%`
      })
    }
    
    // æ£€æŸ¥å“åº”æ—¶é—´å¼‚å¸¸
    if (aggregation.metrics.averageResponseTime > this.config.alertThresholds.responseTime) {
      this.anomalies.push({
        timestamp: aggregation.timestamp,
        type: 'threshold',
        metric: 'response_time',
        value: aggregation.metrics.averageResponseTime,
        expected: this.config.alertThresholds.responseTime,
        deviation: aggregation.metrics.averageResponseTime - this.config.alertThresholds.responseTime,
        confidence: 0.8,
        description: `å¹³å‡å“åº”æ—¶é—´ ${aggregation.metrics.averageResponseTime.toFixed(2)}ms è¶…è¿‡é˜ˆå€¼ ${this.config.alertThresholds.responseTime}ms`
      })
    }
  }
  
  private checkErrorSpike(): void {
    const now = Date.now()
    const recentErrors = this.logBuffer.filter(entry => 
      entry.level >= LogLevel.ERROR && 
      now - entry.timestamp < 300000 // æœ€è¿‘5åˆ†é’Ÿ
    )
    
    if (recentErrors.length > 10) { // 5åˆ†é’Ÿå†…è¶…è¿‡10ä¸ªé”™è¯¯
      this.anomalies.push({
        timestamp: now,
        type: 'spike',
        metric: 'error_count',
        value: recentErrors.length,
        expected: 5,
        deviation: recentErrors.length - 5,
        confidence: 0.85,
        description: `æ£€æµ‹åˆ°é”™è¯¯æ¿€å¢ï¼š5åˆ†é’Ÿå†…å‘ç”Ÿ ${recentErrors.length} ä¸ªé”™è¯¯`
      })
    }
  }
  
  private cleanupExpiredData(): void {
    const cutoff = Date.now() - this.config.retentionPeriod
    
    // æ¸…ç†è¿‡æœŸæ—¥å¿—
    this.logBuffer = this.logBuffer.filter(entry => entry.timestamp > cutoff)
    
    // æ¸…ç†è¿‡æœŸèšåˆæ•°æ®
    this.aggregations = this.aggregations.filter(agg => agg.timestamp > cutoff)
    
    // æ¸…ç†è¿‡æœŸå¼‚å¸¸
    this.anomalies = this.anomalies.filter(anomaly => anomaly.timestamp > cutoff)
  }
  
  private getDefaultConfig(): LogAnalysisConfig {
    return {
      aggregationInterval: 60000, // 1åˆ†é’Ÿ
      retentionPeriod: 24 * 60 * 60 * 1000, // 24å°æ—¶
      alertThresholds: {
        errorRate: 0.05, // 5%
        warningRate: 0.1, // 10%
        responseTime: 5000 // 5ç§’
      },
      enableRealTimeAnalysis: true,
      enablePatternDetection: true,
      enableAnomalyDetection: true
    }
  }
}

// å¯¼å‡ºå•ä¾‹å®ä¾‹
export const logAnalyzer = LogAnalyzer.getInstance()

// åœ¨å¼€å‘ç¯å¢ƒä¸­æŒ‚è½½åˆ°å…¨å±€
if (import.meta.env.DEV) {
  (window as any).logAnalyzer = logAnalyzer
  console.log('ğŸ“Š æ—¥å¿—åˆ†æå™¨å·²æŒ‚è½½åˆ° window.logAnalyzer')
}
